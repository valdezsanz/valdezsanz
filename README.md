## üôã‚Äç‚ôÇÔ∏è Acerca de Mi üôã‚Äç‚ôÇÔ∏è

  Mi nombre es Valdez nahuel y soy un Analista de datos desempe√±andome actualmente como trainee de Business Intelligence. Cuento con formaci√≥n en ingenier√≠a electromec√°nica y experiencia como supervisor en un taller mec√°nico.

## üöÄ Mis inicios en Data üöÄ
  A mediados de 2022 me preguntaron si era posible mostrar mas informacion de la que estaba disponible en la pagina web donde se cargaban los datos de las revisiones tecnicas que realizabamos en nuestro taller.
  
  El requerimiento era saber, entre otras cosas, la cantidad de vehiculos revisadas en los ultimos 365 dias. 
  
  La web contaba con un tablero donde el rango maximo de fechas a mostrar era de un mes, por lo que hasta el momento se sumaban manualmente los resultados hasta llegar a los 365 dias.
  
  Tenia en ese entonces un conocimiento basico de python (lo habia utilizado para automatizar cosas como cambiar nombres de archivos en mi pc) por lo que dije que si al proyecto y empece a trabajar en el en mi tiempo libre .
  
  Utilizando librerias de web scraping consegui los datos necesarios en csv, y ahora tocaba investigar como llevar eso a un tablero para mostrar las estadisticas que necesitaba mi jefe.
  
  Aprendi sobre la libreria pandas , y mediante mucha prueba y error logre unir todos los archivos y limpiarlos para tener solo la informacion necesaria.
  
  Ahora estaba de nuevo en mi confort zone, era cuestion de utilizar Excel , cargar el csv y hacer la tabla y su grafico. 
  
  Pero me encontre con un gran problema: el csv contenia mas de 2 millones de filas. Por lo que no podia trabajar en excel. 
  
  Como el requerimiento no era tener los datos de las revisiones individuales, sino solo datos estadisticos, volvi a python y con pandas agrupe las revisiones por dia. 
  
  Ahora si tenia ya todo listo para mostrar mis resultados en excel, hice una tabla pivot junto con un grafico y un filtro para las fechas. Mi jefe quedo satisfecho con lo que hice pero no se daba idea de la magnitud de cosas que tuve que aprender y lo que desperto en mi.
  
  Una inmensa curiosidad y ganas de saber mas sobre el mundo de los datos.En esas semanas de investigacion me tope con muchas sugerencias de aplicaciones hechas especificamente para lo que yo estaba tratando de hacer, me fui dando cuenta de que excel es solo la punta del iceberg. 
  
  Habia Aplicaciones para hacer tablas y graficos dinamicos de verdad, no lo que venia haciendo yo en excel hace ya 5 a√±os, una forma de guardar datos mejor que en tablas de excel y archivos csv, y un lenguaje dedicado a hacer consultas a una base de datos.
  
  Es asi entonces que tome la decision de transicionar a una nueva area, realizando cursos y aprendiendo por mi cuenta sobre las bases del analisis de datos y las herramientas necesarias para resolver cualquier tipo de problematica orientada a datos.
  
  
## üìö Portfolio üìö
En mi [repo](https://github.com/valdezsanz?tab=repositories) se encuentran mis proyectos. Los mas destacados son :
### [RTO analysis](https://github.com/valdezsanz/RTO_analysis-Python-PowerBI): 
El objetivo fue realizar un dashboard para control de las metricas mas importantes del negocio, y responder preguntas acerca de las revisiones realizadas en un taller mecanico en el cual trabaje como supervisor de linea de inspeccion.

Es una mejora (muy grande) al primer proyecto que hice relacionado a datos para la empresa que trabajaba.
En su momento lo hice con un script muy basico de python y en Excel.

Herramientas utilizadas : 
- Python para hacer el web Scraping ,limpiar los datos y realizar el analisis de estos 
- Power Bi para desarrollar el dashboard 

[ver dashboard](https://app.powerbi.com/view?r=eyJrIjoiZDMyMjczMGUtMDllNi00ZWMxLTljNjItNmRiODcxY2ZlMjVlIiwidCI6IjNlNTMyODRhLWVlZjAtNDI3My05ZTZjLWE2NjA2YmJlMzNiMSJ9)

### [Analisis Programa Previaje](https://github.com/valdezsanz/Programa-Previaje-Argentina):
El objetivo fue Hacer un analisis y un dashboard informativo resumiendo la evolucion del programa turistico argentino durante sus tres ediciones

Herramientas utilizadas: 
- Python para limpiar datos y realizar el analisis
- Power Bi para desarrollar el dashboard

[ver dashboard](https://app.powerbi.com/view?r=eyJrIjoiMjI3YjIwN2UtNGQyYi00OWY2LTlmYjctODNiZGQwMmY2YTUyIiwidCI6IjNlNTMyODRhLWVlZjAtNDI3My05ZTZjLWE2NjA2YmJlMzNiMSJ9)

### [LandBot cleaning - Fuzzy Matching](https://github.com/valdezsanz/fuzzy_matching):
Script de Python hecho para limpiar datos provenientes de conversaciones de usuarios con bots de LandBot 

Las preguntas y respuestas contaban con diferencias dependiendo de la version de la aplicacion. 
por ejemplo la misma pregunta se podria realizar de esta manera:


1- Do you enjoy talking long walks 

1- What about long walks, do you enjoy them?

El dataset para este script no estara disponible pero me parece interesante mostrar el scrpit y la manera en que solucione este problema

Herramientas utilizadas: 
- Python para limpiar datos

## üìñHomework - Certificationsüìñ
### [Sales Method](https://github.com/valdezsanz/sales_method-Python):
Proyecto realizado como parte de la certificacion Data Analyst Professional en la plataforma DataCamp .El objetivo fue Analizar el mejor m√©todo de ventas 

Herramientas utilizadas: Python

### [Food Claims](https://github.com/valdezsanz/Food_Claims-SQL):
Proyecto realizado como parte de la certificacion Data Analyst Associate

Herramientas utilizadas : PostgreSQL .


## üõ†Ô∏è Herramientas
- Bases de Datos: SQL (PostgreSQL, Google BigQuery)
- Python: NumPy, Pandas
- Visualizacion: PowerBI, Matplotlib, Seaborn

## üôåüèª Contacto
- [Linkedin](https://www.linkedin.com/in/valdeznahuel/)
- [Mail](mailto:valdezsanz@gmail.com)
